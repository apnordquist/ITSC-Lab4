
"""
malwaredetector.py

Android Malware Detector using SecML and SVM on the DrebinRed dataset.
Covers environment setup, data loading, preprocessing, SVM training,
evaluation, post-hoc explanations, adversarial example generation,
and security evaluation.
"""

import re
import numpy as np
import matplotlib.pyplot as plt

# ─── SecML Imports ─────────────────────────────────────────────────────────────
import secml
from secml import settings
from secml.array import CArray
from secml.ml.kernels import CKernelRBF
from secml.ml.classifiers import CClassifierSVM
from secml.ml.peval.metrics import (
    CMetricAccuracy, CMetricF1, CMetricDetectionRate
)
from secml.data.splitter import CTrainTestSplit
from secml.utils import fm, pickle_utils
from secml.utils.download_utils import dl_file_gitlab
from secml.adv.attacks import CAttackEvasionPGD
from secml.adv.evaluators import CSecEval
from secml.explanation import CExplainerGradient

# ─── sklearn Imports ──────────────────────────────────────────────────────────
from sklearn.preprocessing import MaxAbsScaler
from sklearn.metrics import roc_curve, auc


def download_and_load_drebin():
    """Downloads (if needed) and loads the DrebinRed dataset via SecML."""
    repo_url   = "https://gitlab.com/secml/secml-zoo"
    file_name  = "drebin-reduced.tar.gz"
    file_path  = "datasets/DrebinRed/" + file_name
    output_dir = fm.join(settings.SECML_DS_DIR, "drebin-red")
    md5        = "ecf87ddedf614dd53b89285c29cf1caf"
    ds_path    = fm.join(output_dir, file_name)

    if not fm.file_exist(ds_path):
        try:
            # match SecML version branch (e.g. v0.13)
            branch = "v" + re.search(r'\d+\.\d+', secml.__version__).group(0)
            dl_file_gitlab(repo_url, file_path, output_dir,
                           branch=branch, md5=md5)
        except Exception:
            dl_file_gitlab(repo_url, file_path, output_dir, md5=md5)

    return pickle_utils.load(ds_path)


def explore_dataset(ds):
    print("\n=== Dataset Exploration ===")
    print("Total samples:      ", ds.num_samples)
    print("Number of features: ", ds.num_features)
    y = ds.Y.tondarray().flatten()
    u, c = np.unique(y, return_counts=True)
    print(f"Benign (0): {c[0]}, Malicious (1): {c[1]}")


def preprocess_and_split(ds):
    print("\n=== Preprocessing & Train/Test Split ===")
    splitter = CTrainTestSplit(train_size=0.8, random_state=0)
    train_ds, test_ds = splitter.split(ds)
    print(f"Training samples: {train_ds.num_samples}")
    print(f"Testing  samples: {test_ds.num_samples}")

    # SecML stores sparse features; convert + scale via sklearn
    X_train = train_ds.X.tosparse().get_data()
    X_test  = test_ds.X.tosparse().get_data()
    scaler  = MaxAbsScaler().fit(X_train)
    train_ds.X = CArray(scaler.transform(X_train))
    test_ds.X  = CArray(scaler.transform(X_test))

    return train_ds, test_ds


def train_svm(train_ds):
    print("\n=== Training SVM Classifier ===")
    svm = CClassifierSVM(kernel=CKernelRBF(), C=1.0, gamma="auto")
    svm.fit(train_ds.X, train_ds.Y)
    y_pred_train = svm.predict(train_ds.X)
    acc_train    = CMetricAccuracy().performance_score(train_ds.Y, y_pred_train)
    print(f"Training Accuracy: {acc_train:.2%}")
    return svm


def evaluate_model(svm, test_ds):
    print("\n=== Model Evaluation ===")
    y_true  = test_ds.Y.tondarray().flatten()
    y_score = svm.decision_function(test_ds.X).ravel()
    y_pred  = svm.predict(test_ds.X).ravel()

    acc = CMetricAccuracy().performance_score(test_ds.Y, y_pred)
    f1  = CMetricF1().performance_score(test_ds.Y, y_pred)
    dr  = CMetricDetectionRate(fpr=0.01).performance_score(test_ds.Y, y_score)

    print(f"Accuracy:      {acc:.2%}")
    print(f"F1 Score:      {f1:.2%}")
    print(f"DR @1% FPR:    {dr:.2%}")

    # Confusion matrix
    cm = CMetricAccuracy.create("confusion_matrix")\
          .performance(test_ds.Y, y_pred)
    print("\nConfusion Matrix:\n", cm)

    # Plot ROC
    fpr_arr, tpr_arr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr_arr, tpr_arr)
    plt.figure()
    plt.plot(fpr_arr, tpr_arr, label=f"AUC = {roc_auc:.2f}")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()


def explain_model(svm, train_ds, test_ds):
    print("\n=== Post‑hoc Explanation ===")
    explainer = CExplainerGradient(svm, train_ds.X)
    # pick the first malicious test sample
    idx = np.where(test_ds.Y.tondarray().flatten() == 1)[0][0]
    imp = explainer.explain(test_ds.X[idx])
    print("Top 5 feature indices driving malware decision:",
          imp.topk(5))


def generate_adversarial(svm, test_ds):
    print("\n=== Adversarial Example Generation ===")
    # pick first benign sample
    idx = np.where(test_ds.Y.tondarray().flatten() == 0)[0][0]
    x0  = test_ds.X[idx]
    attack = CAttackEvasionPGD(classifier=svm, init_point=x0,
                               lb=0., ub=1., dmax=10)
    x_adv, score_adv = attack.run()
    print(f"Adversarial created (dmax={attack.dmax}), score change: {score_adv:.4f}")


def security_evaluation(svm, test_ds):
    print("\n=== Security Evaluation Curve ===")
    attack   = CAttackEvasionPGD(classifier=svm, init_point=None, lb=0., ub=1.)
    sec_eval = CSecEval(classifier=svm, evasion_attack=attack)
    feature_range = list(range(0, 51, 5))
    results       = sec_eval.run(test_ds.X, test_ds.Y, feature_range=feature_range)

    plt.figure()
    plt.plot(feature_range, [results[n] for n in feature_range], marker="o")
    plt.xlabel("Number of Features Modified")
    plt.ylabel("Detection Rate")
    plt.title("Security Evaluation Curve")
    plt.show()


def main():
    ds        = download_and_load_drebin()
    explore_dataset(ds)
    train_ds, test_ds = preprocess_and_split(ds)
    svm       = train_svm(train_ds)
    evaluate_model(svm, test_ds)
    explain_model(svm, train_ds, test_ds)
    generate_adversarial(svm, test_ds)
    security_evaluation(svm, test_ds)


if __name__ == "__main__":
    main()
